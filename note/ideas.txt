Consider doing a stack-based language in the intro section. That will give
readers some practice thinking in terms of stacks, which will then come in
handy when we get to the bytecode VM at the end.

See: https://leanpub.com/readevalprintlove003/read

Talk about how being concatenative helps compiling. To compile an expression,
we just concatenate compiling the subexpressions.

--

When talking about whether or not strings and numbers can have properties added,
consider what that would mean for equality on them.

--

When talking about early and late binding, use an example like this:

if (false) {
  var a = 1;
  var a = 2; // error here?
}

--

Define "parameter" and "argument" early on.

--

When talking about comparison operators, talk about how allowing comparison on
non-numeric types can be handy for polymorphic sorted collections.

--

Talk about what the stack frame would look like if we allowed variables to be
declared in the middle of an expression.

--

Question: Smalltalk implementations doesn't have to check that the number of
arguments to a method matches the number of parameters it expects. Why not?

--

Regarding error handling: a language should either give you enough features to
let you prevent an error, or to handle it. For example, in Vox, there's no way
to check the type of an object, but also you get a runtime error that you can't
catch if you pass an object of the wrong type to an operator. That's bad.

--

Consider interleaving a couple of "essays" that talk about more subjective
aspects of language design:

- The "novelty budget" and choosing which things to keep familiar and which to
  keep new.

- Learnability versus consistency. Being internally consistent leads to a
  simpler, more elegant language, but doesn't leverage what the user already
  knows.

- Building an entire ecosystem: implementation, spec, core libraries, docs, etc.

--

We don't have toString(), nor does "+" allow mixing string arguments with other
types. That's pretty limiting.

--

Mention in intro that code is lightly documented because prose itself is docs.
Real code should have more docs.

--

When talking about bound functions, explain how this is where JavaScript's
confusing "this" behavior comes from.

Explain how in Vox it's important that closurizing does bind "this" because the
body of the method presumes "this" is an instance of the surrounding class, in
particular around how "super" is handled.

--

When we first talk about compiling Vox, explain that "compiling" doesn't always
mean "statically typed". See:

http://akaptur.com/blog/2013/12/03/introduction-to-the-python-interpreter-4/

--

One way to look at bytecode is a really dense serialization of the AST.

--

When implementing strings, talk about encodings and character representations.

--

Discuss symbols versus strings. Symbols are usually based on source code, not
strings created at runtime from things like concatenation. Some languages let
you explicitly "intern" a string that was created dynamically. Lua implicitly
interns all strings.

Some languages GC interned strings (Lua), some do not. To GC them, insert step
between mark and sweep that removes unmarked symbols from symbol table.

Key difference between symbols and strings is that symbols are canonicalized:
same sequence of characters always represented by exact same symbol object. Lets
you rely on reference equality to compare strings, which is much faster.

In source code, same sequence of characters may appear multiple times. So must
deduplicate at some point. (If language supports explicit interning, that API
must dedupe too.) Usually done during parsing or compiling.

Deduplication takes a little time, but only has to be done once and amortizes
cost of comparing strings many times later.

Dedupe using hash table: O(1). Could theoretically use something like red-black
tree or maybe even trie or prefix tree, but not done in practice.

Want to use symbols or interned strings for method and field lookup because
they're much faster than string comparison. Because Lua lets you use any string
object, including dynamically-created ones, as table keys, it interns all
strings. Vox doesn't have syntax or API for that, so we don't need to. Can
treat symbols and strings separately.

--

Mention (or challenge question?) about adding support for "break" to loops.

--

Most other sources use "symbol table" to refer to the data structure built up
during compilation that tracks types and lexical scopes. Though this source:

http://arantxa.ii.uam.es/~modonnel/Compilers/04_SymbolTablesI.pdf

distinguishes a few different kinds of symbol tables.

Things seem a little different in a dynamically typed language. In a static one,
the symbol table is mainly to refer to declarations of identifiers so things
like types and function calls can be resolved. But you eventually compile down
to lower level code that no longer needs to refer to the symbol. Similar to how
we handle local variables now in the compiler.

But for method and field names, "symbol" means something a little different,
more like what it means in the Lisp sense.

http://www.lispworks.com/documentation/lw70/CLHS/Body/t_symbol.htm
https://en.wikipedia.org/wiki/Symbol_(programming)
https://en.wikipedia.org/wiki/String_interning

--

When explaining IS_XXX() and AS_XXX() macros, talk about how the AS ones do
not check the value and we're responsible for calling the IS one first unless
we are sure it's the right type. If we had a static type system, would not
need the IS checks at runtime.

--

While I don't want to talk too much about how to organize the code, I do need
to specify which source files functions go in in cvox, since it uses "static"
function declarations.

--

When talking about error recovery, note that it's less of a big deal today.
Back when machines were super slow, compile runs were infrequent and it was
important to report as many errors correctly as possible in a single run.

Today, compiling is fast and users often only look at the first error in each
compile run, fix it, and retry. Means we don't need very sophisticated error
recovery.

--

Note that we use an EOF token instead of just checking for the end of the token
list because the end of the file may be on a different line than the last
non-whitespace token.

--

When talking about stack overflow detection, consider a few approaches:

- Ensure there are as many stack slots as possibly needed for each call frame.
  Then we just need to detect call frame overflow. Can use a lot of stack space.
  Simple and fast.

- Check on each push. Simple but really slow.

- Calculate max stack for each function. Good compromise. Little tedious to
  calculate in compiler.

--

When talking about compilers and interpreters, talk about what a "runtime" is
GC, object representation, etc. and where it lives. Many compiled languages
have no runtime. Others compile the runtime into the executable (Go, Haskell).
Interpreters host the runtime.

--

Talk about but don't bother implementing checks for duplicate method
definitions.

--

Note that interning relies on strings being immutable!

--

When parsing number literals, mention checking for infinity.

--

Talk about late and early binding. Motivating example:

    var a = "global";
    fun outer() {
      fun inner() {
        print(a);
      }

      inner();
      var a = "outer";
      inner();
    }

This should print "global" twice, not "global" then "outer".

--

Talk about how we handle unknown identifiers. Because we want to support the
REPL and forward references to global vars, we allow them. A stricter language
would not.

Should our interpreter behave differently when run in REPL versus file mode?

--

When introducing statements in the variables chapter explain that one difference
is that statements are purely about side effects since they produce no value.
A variable declaration is mainly for its side effect -- it modifies the
environment.

--

When explaining visitor pattern, explain context parameter that is often used.

--

The error message on:

  if (true) var foo;

(i.e. a declaration where a statement is expected) isn't very helpful. Talk
about parsing a larger grammar to improve error messages. So, here, allow
parsing a declaration even though it isn't valid.

--

Note that we're using keywords for "and" and "or" instead of "||" and "&&"
since we don't define the bitwise forms and it's weird to lex "||" without "|".

--

Challenge for scanning chapter: Add /* */ comments. Should they nest?

--

When implementing valueEquals() discuss using memcmp() to compare the unions
and how that doesn't work because of padding bytes, etc.

--

Benchmarking string equality using interning versus comparing length and bytes:

comparing bytes:

          overhead   elapsed    equals
bytes     1.194243  1.977721  0.783478
interned  1.171333  1.364724  0.193391

Here, "overhead" is the time spent in the benchmark doing other stuff (looping,
loading vars, etc.). Elapsed is total execution time of the benchmark. Equals
is the difference, showing just the time spent doing the "==".

(Oof, just realized I probably forgot to turn off GC stress testing for this.
And ran a debug build.)

--

In intro, explain prereqs: expect them to be able to set up makefile or project
or whatever to build their code.
